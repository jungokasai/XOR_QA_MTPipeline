python tokenizers/tokenizer.py --lang ja --in-file ~/data-bin/master/kftt-data-1.0.stanford/ja-en/xor/xor_valid.raw.ja --out-file ~/data-bin/master/kftt-data-1.0.stanford/ja-en/xor/xor_valid.stanford.ja
python subword-nmt/apply_bpe.py -c ~/data-bin/master/kftt-data-1.0.stanford/ja-en/bpe.32000  < ~/data-bin/master/kftt-data-1.0.stanford/ja-en/xor/xor_valid.stanford.ja  > ~/data-bin/master/kftt-data-1.0.stanford/ja-en/xor/xor_valid.stanford.bpe.ja
python preprocess.py --destdir ~/data-bin/master/kftt-data-1.0.stanford/ja-en/xor/ --source-lang ja --target-lang en --validpref ~/data-bin/master/kftt-data-1.0.stanford/ja-en/xor/xor_valid.stanford.bpe --workers 20 --srcdict ~/data-bin/master/kftt-data-1.0.stanford/ja-en/dict.ja.txt --tgtdict ~/data-bin/master/kftt-data-1.0.stanford/ja-en/dict.en.txt --only-source > ~/data-bin/master/kftt-data-1.0.stanford/ja-en/xor/preprocess.log 
python generate.py ~/data-bin/master/kftt-data-1.0.stanford/ja-en/xor/ --path trans_jaen_stan_6-6/checkpoint_best.pt --task translation --max-sentences 10 --beam 5 --gen-subset valid --remove-bpe > ~/data-bin/master/kftt-data-1.0.stanford/ja-en/xor/xor_valid.out
cat ~/data-bin/master/kftt-data-1.0.stanford/ja-en/xor/xor_valid.out | grep -P ‘^H’ | cut -c3- | sort -n -k 1 |uniq | cut -f 2 > ~/data-bin/master/kftt-data-1.0.stanford/ja-en/xor/xor_valid.hyp
cat ~/data-bin/master/kftt-data-1.0.stanford/ja-en/xor/xor_valid.hyp  | perl detokenizer.perl  > ~/data-bin/master/kftt-data-1.0.stanford/ja-en/xor/xor_valid.hyp.detok 
